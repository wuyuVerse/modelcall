"""æ•°æ®è’¸é¦ä»»åŠ¡æ‰§è¡Œå™¨"""

from pathlib import Path
from typing import Dict, Any

import yaml

from .base_runner import BaseTaskRunner
from ...data_distillation.chatml_converter import ChatMLConverter
from ...data_distillation.jsonl_merger import JSONLMerger
from ...data_distillation.response_generator import ResponseGenerator


class DistillationTaskRunner(BaseTaskRunner):
    """æ•°æ®è’¸é¦ä»»åŠ¡æ‰§è¡Œå™¨"""
    
    async def run(self, job_index: int = 0, world_size: int = 1):
        """
        è¿è¡Œæ•°æ®è’¸é¦ä»»åŠ¡
        
        Args:
            job_index: ä½œä¸šç´¢å¼•
            world_size: ä½œä¸šæ€»æ•°
        """
        distillation_config = self.config.get("distillation")
        if not distillation_config:
            self.logger.error("æ•°æ®è’¸é¦é…ç½®æœªæ‰¾åˆ°")
            return
        
        step = distillation_config.get("step")
        self.logger.info(f"ğŸ”„ å¼€å§‹æ•°æ®è’¸é¦æ­¥éª¤: {step}")
        
        if step == "chatml_conversion":
            await self._run_chatml_conversion(distillation_config)
        elif step == "jsonl_merge":
            await self._run_jsonl_merge(distillation_config)
        elif step == "generate_response":
            await self._run_generate_response(distillation_config)
        else:
            self.logger.error(f"æœªçŸ¥çš„æ•°æ®è’¸é¦æ­¥éª¤: {step}")
    
    async def _run_chatml_conversion(self, distillation_config: Dict[str, Any]):
        """æ‰§è¡ŒChatMLæ ¼å¼è½¬æ¢"""
        self.logger.info("ğŸ“ æ‰§è¡ŒChatMLæ ¼å¼è½¬æ¢...")
        
        converter = ChatMLConverter(
            dataset_config_path=distillation_config.get("dataset_config_path"),
            input_dir=distillation_config.get("input_dir"),
            output_dir=distillation_config.get("output_dir"),
            num_processes=distillation_config.get("num_processes"),
            keep_raw_data=distillation_config.get("keep_raw_data", True),
            add_system_prompt=distillation_config.get("add_system_prompt", False),
            system_prompt=distillation_config.get("system_prompt", "You are a helpful assistant and an expert coder."),
            continue_mode=distillation_config.get("continue_mode", True)
        )
        
        converter.run()
        self.logger.info("âœ… ChatMLæ ¼å¼è½¬æ¢å®Œæˆ")
    
    async def _run_jsonl_merge(self, distillation_config: Dict[str, Any]):
        """æ‰§è¡ŒJSONLæ–‡ä»¶åˆå¹¶"""
        self.logger.info("ğŸ”— æ‰§è¡ŒJSONLæ–‡ä»¶åˆå¹¶...")
        
        # åŠ è½½åˆå¹¶é…ç½®
        merge_config_path = distillation_config.get("merge_config_path")
        with open(merge_config_path, 'r', encoding='utf-8') as f:
            merge_config = yaml.safe_load(f)
        
        base_input_dir = Path(distillation_config.get("base_input_dir"))
        base_output_dir = Path(distillation_config.get("base_output_dir"))
        chunk_size = distillation_config.get("chunk_size", 1000)
        
        # è·å–è¦æ‰§è¡Œçš„åˆå¹¶ç»„
        selected_groups = distillation_config.get("merge_groups", [])
        all_merge_groups = merge_config.get("merge_groups", [])
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæˆ–ä¸ºç©ºåˆ—è¡¨ï¼Œåˆ™æ‰§è¡Œæ‰€æœ‰ç»„
        if not selected_groups:
            groups_to_process = all_merge_groups
        else:
            # åªå¤„ç†æŒ‡å®šçš„ç»„
            groups_to_process = [g for g in all_merge_groups if g["name"] in selected_groups]
        
        if not groups_to_process:
            self.logger.warning("æ²¡æœ‰æ‰¾åˆ°è¦å¤„ç†çš„åˆå¹¶ç»„")
            return
        
        self.logger.info(f"æ‰¾åˆ° {len(groups_to_process)} ä¸ªåˆå¹¶ç»„éœ€è¦å¤„ç†")
        
        # é€ä¸ªå¤„ç†åˆå¹¶ç»„
        for group in groups_to_process:
            group_name = group["name"]
            output_file = group["output_file"]
            input_files = group["input_files"]
            
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"ğŸ”„ å¤„ç†åˆå¹¶ç»„: {group_name}")
            self.logger.info(f"   è¾“å…¥æ–‡ä»¶æ•°: {len(input_files)}")
            self.logger.info(f"   è¾“å‡ºæ–‡ä»¶: {output_file}")
            
            # æ„å»ºå®Œæ•´è·¯å¾„
            full_input_files = [str(base_input_dir / f) for f in input_files]
            full_output_path = str(base_output_dir / output_file)
            
            # åˆ›å»ºåˆå¹¶å™¨å¹¶æ‰§è¡Œ
            merger = JSONLMerger(
                input_files=full_input_files,
                output_path=full_output_path,
                chunk_size=chunk_size
            )
            
            total = merger.run()
            self.logger.info(f"âœ… åˆå¹¶ç»„ '{group_name}' å®Œæˆï¼Œå…±åˆå¹¶ {total} æ¡è®°å½•")
        
        self.logger.info(f"\n{'='*60}")
        self.logger.info("âœ… æ‰€æœ‰JSONLæ–‡ä»¶åˆå¹¶å®Œæˆ")
    
    async def _run_generate_response(self, distillation_config: Dict[str, Any]):
        """æ‰§è¡Œå“åº”ç”Ÿæˆ"""
        self.logger.info("ğŸ¤– æ‰§è¡Œå“åº”ç”Ÿæˆ...")
        
        # åŠ è½½å“åº”é…ç½®
        response_config_path = distillation_config.get("response_config_path")
        with open(response_config_path, 'r', encoding='utf-8') as f:
            response_config = yaml.safe_load(f)
        
        client_config = response_config.get("client_config", {})
        chat_config = response_config.get("chat_config", {})
        
        # éªŒè¯å¿…éœ€çš„é…ç½®
        if "model" not in chat_config:
            self.logger.error("Model name is required in chat_config")
            return
        
        input_path = distillation_config.get("input_path")
        output_path = distillation_config.get("output_path")
        concurrency = distillation_config.get("concurrency", 20)
        batch_size = distillation_config.get("batch_size", 20)
        flush_interval_secs = distillation_config.get("flush_interval_secs", 2.0)
        retry_mode = distillation_config.get("retry_mode", False)
        resume_mode = distillation_config.get("resume_mode", True)
        
        self.logger.info(f"è¾“å…¥æ–‡ä»¶: {input_path}")
        self.logger.info(f"è¾“å‡ºç›®å½•: {output_path}")
        self.logger.info(f"æ¨¡å‹: {chat_config.get('model')}")
        self.logger.info(f"å¹¶å‘æ•°: {concurrency}")
        self.logger.info(f"æ‰¹é‡å¤§å°: {batch_size}")
        self.logger.info(f"é‡è¯•æ¨¡å¼: {'å¯ç”¨' if retry_mode else 'ç¦ç”¨'}")
        self.logger.info(f"æ–­ç‚¹ç»­ä¼ : {'å¯ç”¨' if resume_mode else 'ç¦ç”¨'}")
        
        # åˆ›å»ºå“åº”ç”Ÿæˆå™¨å¹¶æ‰§è¡Œ
        generator = ResponseGenerator(
            input_path=input_path,
            output_path=output_path,
            client_config=client_config,
            chat_config=chat_config,
            concurrency=concurrency,
            batch_size=batch_size,
            flush_interval_secs=flush_interval_secs,
            retry_mode=retry_mode,
            resume_mode=resume_mode
        )
        
        await generator.run()
        self.logger.info("âœ… å“åº”ç”Ÿæˆå®Œæˆ")

