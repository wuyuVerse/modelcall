"""æ•°æ®è¯„åˆ†ä»»åŠ¡æ‰§è¡Œå™¨"""

from typing import Dict, Any

from .base_runner import BaseTaskRunner
from ...data_scoring.concurrent_processor import ConcurrentFileProcessor


class ScoringTaskRunner(BaseTaskRunner):
    """æ•°æ®è¯„åˆ†ä»»åŠ¡æ‰§è¡Œå™¨"""
    
    def __init__(self, config: Any, logger: Any, fs_cfg: Dict[str, Any], paths: Dict[str, str]):
        """
        åˆå§‹åŒ–æ•°æ®è¯„åˆ†æ‰§è¡Œå™¨
        
        Args:
            config: ä»»åŠ¡é…ç½®ï¼ˆEasyDictï¼‰
            logger: æ—¥å¿—ç®¡ç†å™¨
            fs_cfg: æ–‡ä»¶ç³»ç»Ÿé…ç½®
            paths: è§£æåçš„è·¯å¾„å­—å…¸
        """
        super().__init__(config, logger, fs_cfg)
        self.paths = paths
    
    def create_processor(self, job_index: int = 0, world_size: int = 1, run_index: int = 1) -> ConcurrentFileProcessor:
        """
        åˆ›å»ºå¤„ç†å™¨å®ä¾‹
        
        Args:
            job_index: ä½œä¸šç´¢å¼•
            world_size: ä½œä¸šæ€»æ•°
            run_index: è¿è¡Œè½®æ¬¡
            
        Returns:
            ConcurrentFileProcessor å®ä¾‹
        """
        paths = self.paths.copy()
        
        # å¦‚æœæ˜¯å¤šè½®è¿è¡Œï¼Œè°ƒæ•´è¾“å‡ºè·¯å¾„
        if self.config.distributed.get("num_runs", 1) > 1:
            output_folder = paths["output_folder"].replace("{run_index}", str(run_index))
            paths["output_folder"] = output_folder
        
        # åˆ›å»ºå¤„ç†å™¨
        processor = ConcurrentFileProcessor(
            input_folder=paths["input_folder"],
            output_folder=paths["output_folder"],
            stat_folder=paths["stat_folder"],
            model_config_path=paths["model_config_path"],
            prompt_config_path=paths["prompt_config_path"],
            fs_cfg=self.fs_cfg,
            max_concurrent_files=self.config.concurrency.max_concurrent_files,
            max_concurrent_requests=self.config.concurrency.max_concurrent_requests,
            chunk_size=self.config.concurrency.chunk_size,
            parquet_save_interval=self.config.concurrency.parquet_save_interval,
            input_key=self.config.data.input_key,
            prompt_format_key=self.config.data.prompt_format_key,
            enable_format_validation_retry=self.config.retry.enable_format_validation_retry
        )
        
        return processor
    
    async def run(self, job_index: int = 0, world_size: int = 1):
        """
        è¿è¡Œæ•°æ®è¯„åˆ†ä»»åŠ¡
        
        Args:
            job_index: ä½œä¸šç´¢å¼•
            world_size: ä½œä¸šæ€»æ•°
        """
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨åˆ†å¸ƒå¼
        if self.config.distributed.get("enabled", False) and world_size > 1:
            self.logger.info(f"ğŸ”€ åˆ†å¸ƒå¼æ¨¡å¼å·²å¯ç”¨")
        
        # å¤šè½®è¿è¡Œæ”¯æŒ
        num_runs = self.config.distributed.get("num_runs", 1)
        
        for run_index in range(1, num_runs + 1):
            if num_runs > 1:
                self.logger.info(f"ğŸ¯ === ç¬¬ {run_index}/{num_runs} è½®è¿è¡Œ ===")
            
            # åˆ›å»ºå¤„ç†å™¨
            processor = self.create_processor(job_index, world_size, run_index)
            
            # è·å–è¦å¤„ç†çš„æ–‡ä»¶
            debug_files = self.config.debug.max_files if self.config.debug.enabled else None
            files = processor.get_files_to_process(
                debug_files=debug_files,
                job_index=job_index,
                world_size=world_size
            )
            
            if not files:
                self.logger.warning(f"æ²¡æœ‰æ‰¾åˆ°è¦å¤„ç†çš„æ–‡ä»¶ (Job {job_index}/{world_size})")
                continue
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.logger.update_stats(total_files=len(files))
            self.logger.info(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶éœ€è¦å¤„ç†")
            
            # è¿è¡Œå¤„ç†
            debug_items = self.config.debug.max_items_per_file if self.config.debug.enabled else None
            await processor.process_files(
                files=files,
                resume=self.config.options.get('main_resume', self.config.options.get('resume', True)),
                debug_items=debug_items,
                delete_existing=self.config.options.delete_existing
            )
            
            self.logger.info(f"âœ… ç¬¬ {run_index} è½®è¿è¡Œå®Œæˆ")

